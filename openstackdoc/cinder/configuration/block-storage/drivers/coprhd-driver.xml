<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE document PUBLIC "+//IDN docutils.sourceforge.net//DTD Docutils Generic//EN//XML" "http://docutils.sourceforge.net/docs/ref/docutils.dtd">
<!-- Generated by Docutils 0.13.1 -->
<document source="/home/fbaumanis/openstack/soc8_test/openstack_repo/cinder/doc/source/configuration/block-storage/drivers/coprhd-driver.rst">
    <section ids="coprhd-fc-iscsi-and-scaleio-drivers" names="coprhd\ fc,\ iscsi,\ and\ scaleio\ drivers">
        <title>CoprHD FC, iSCSI, and ScaleIO drivers</title>
        <paragraph>CoprHD is an open source software-defined storage controller and API platform.
            It enables policy-based management and cloud automation of storage resources
            for block, object and file storage providers.
            For more details, see <reference name="CoprHD" refuri="http://coprhd.org/">CoprHD</reference><target ids="coprhd" names="coprhd" refuri="http://coprhd.org/"></target>.</paragraph>
        <paragraph>EMC ViPR Controller is the commercial offering of CoprHD. These same volume
            drivers can also be considered as EMC ViPR Controller Block Storage drivers.</paragraph>
        <section ids="system-requirements" names="system\ requirements">
            <title>System requirements</title>
            <paragraph>CoprHD version 3.0 is required. Refer to the CoprHD documentation for
                installation and configuration instructions.</paragraph>
            <paragraph>If you are using these drivers to integrate with EMC ViPR Controller, use
                EMC ViPR Controller 3.0.</paragraph>
        </section>
        <section ids="supported-operations" names="supported\ operations">
            <title>Supported operations</title>
            <paragraph>The following operations are supported:</paragraph>
            <bullet_list bullet="-">
                <list_item>
                    <paragraph>Create, delete, attach, detach, retype, clone, and extend volumes.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Create, list, and delete volume snapshots.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Create a volume from a snapshot.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Copy a volume to an image.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Copy an image to a volume.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Clone a volume.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Extend a volume.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Retype a volume.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Get volume statistics.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Create, delete, and update consistency groups.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Create and delete consistency group snapshots.</paragraph>
                </list_item>
            </bullet_list>
        </section>
        <section ids="driver-options" names="driver\ options">
            <title>Driver options</title>
            <paragraph>The following table contains the configuration options specific to the
                CoprHD volume driver.</paragraph>
            <comment xml:space="preserve">Warning: Do not edit this file. It is automatically generated from the
software project's code and your changes will be overwritten.

The tool to generate this file lives in openstack-doc-tools repository.

Please make any changes needed in the code, then run the
autogenerate-config-doc tool from the openstack-doc-tools repository, or
ask for help on the documentation mailing list, IRC channel or meeting.</comment>
            <target refid="cinder-coprhd"></target>
            <table classes="config-ref-table" ids="id2 cinder-coprhd" names="cinder-coprhd">
                <title>Description of Coprhd volume driver configuration options</title>
                <tgroup cols="2">
                    <colspec colwidth="50"></colspec>
                    <colspec colwidth="50"></colspec>
                    <thead>
                        <row>
                            <entry>
                                <paragraph>Configuration option = Default value</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Description</paragraph>
                            </entry>
                        </row>
                    </thead>
                    <tbody>
                        <row>
                            <entry>
                                <paragraph><strong>[DEFAULT]</strong></paragraph>
                            </entry>
                            <entry>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_emulate_snapshot</literal> = <literal>False</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Boolean) True | False to indicate if the storage array in CoprHD is VMAX or VPLEX</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_hostname</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Hostname for the CoprHD Instance</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_password</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Password for accessing the CoprHD Instance</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_port</literal> = <literal>4443</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Port number) Port for the CoprHD Instance</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_project</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Project to utilize within the CoprHD Instance</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_scaleio_rest_gateway_host</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Rest Gateway IP or FQDN for Scaleio</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_scaleio_rest_gateway_port</literal> = <literal>4984</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Port number) Rest Gateway Port for Scaleio</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_scaleio_rest_server_password</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Rest Gateway Password</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_scaleio_rest_server_username</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Username for Rest Gateway</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_tenant</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Tenant to utilize within the CoprHD Instance</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_username</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Username for accessing the CoprHD Instance</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>coprhd_varray</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Virtual Array to utilize within the CoprHD Instance</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>scaleio_server_certificate_path</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Server certificate path</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>scaleio_verify_server_certificate</literal> = <literal>False</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Boolean) verify server certificate</paragraph>
                            </entry>
                        </row>
                    </tbody>
                </tgroup>
            </table>
        </section>
        <section ids="preparation" names="preparation">
            <title>Preparation</title>
            <paragraph>This involves setting up the CoprHD environment first and then configuring
                the CoprHD Block Storage driver.</paragraph>
            <section dupnames="coprhd" ids="id1">
                <title>CoprHD</title>
                <paragraph>The CoprHD environment must meet specific configuration requirements to
                    support the OpenStack Block Storage driver.</paragraph>
                <bullet_list bullet="-">
                    <list_item>
                        <paragraph>CoprHD users must be assigned a Tenant Administrator role or a Project
                            Administrator role for the Project being used. CoprHD roles are configured
                            by CoprHD Security Administrators. Consult the CoprHD documentation for
                            details.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>A CorprHD system administrator must execute the following configurations
                            using the CoprHD UI, CoprHD API, or CoprHD CLI:</paragraph>
                        <bullet_list bullet="-">
                            <list_item>
                                <paragraph>Create CoprHD virtual array</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph>Create CoprHD virtual storage pool</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph>Virtual Array designated for iSCSI driver must have an IP network created
                                    with appropriate IP storage ports</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph>Designated tenant for use</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph>Designated project for use</paragraph>
                            </list_item>
                        </bullet_list>
                    </list_item>
                </bullet_list>
                <note>
                    <paragraph>Use each back end to manage one virtual array and one virtual
                        storage pool. However, the user can have multiple instances of
                        CoprHD Block Storage driver, sharing the same virtual array and virtual
                        storage pool.</paragraph>
                </note>
                <bullet_list bullet="-">
                    <list_item>
                        <paragraph>A typical CoprHD virtual storage pool will have the following values
                            specified:</paragraph>
                        <bullet_list bullet="-">
                            <list_item>
                                <paragraph>Storage Type: Block</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph>Provisioning Type: Thin</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph>Protocol: iSCSI/Fibre Channel(FC)/ScaleIO</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph>Multi-Volume Consistency: DISABLED OR ENABLED</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph>Maximum Native Snapshots: A value greater than 0 allows the OpenStack user
                                    to take Snapshots</paragraph>
                            </list_item>
                        </bullet_list>
                    </list_item>
                </bullet_list>
            </section>
            <section ids="coprhd-drivers-single-back-end" names="coprhd\ drivers\ -\ single\ back\ end">
                <title>CoprHD drivers - Single back end</title>
                <paragraph><strong>cinder.conf</strong></paragraph>
                <enumerated_list enumtype="arabic" prefix="" suffix=".">
                    <list_item>
                        <paragraph>Modify <literal>/etc/cinder/cinder.conf</literal> by adding the following lines,
                            substituting values for your environment:</paragraph>
                        <literal_block highlight_args="{}" language="ini" linenos="False" xml:space="preserve">[coprhd-iscsi]
volume_driver = cinder.volume.drivers.coprhd.iscsi.EMCCoprHDISCSIDriver
volume_backend_name = coprhd-iscsi
coprhd_hostname = &lt;CoprHD-Host-Name&gt;
coprhd_port = 4443
coprhd_username = &lt;username&gt;
coprhd_password = &lt;password&gt;
coprhd_tenant = &lt;CoprHD-Tenant-Name&gt;
coprhd_project = &lt;CoprHD-Project-Name&gt;
coprhd_varray = &lt;CoprHD-Virtual-Array-Name&gt;
coprhd_emulate_snapshot = True or False, True if the CoprHD vpool has VMAX or VPLEX as the backing storage</literal_block>
                    </list_item>
                    <list_item>
                        <paragraph>If you use the ScaleIO back end, add the following lines:</paragraph>
                        <literal_block highlight_args="{}" language="ini" linenos="False" xml:space="preserve">coprhd_scaleio_rest_gateway_host = &lt;IP or FQDN&gt;
coprhd_scaleio_rest_gateway_port = 443
coprhd_scaleio_rest_server_username = &lt;username&gt;
coprhd_scaleio_rest_server_password = &lt;password&gt;
scaleio_verify_server_certificate = True or False
scaleio_server_certificate_path = &lt;path-of-certificate-for-validation&gt;</literal_block>
                    </list_item>
                    <list_item>
                        <paragraph>Specify the driver using the <literal>enabled_backends</literal> parameter:</paragraph>
                        <literal_block xml:space="preserve">enabled_backends = coprhd-iscsi</literal_block>
                        <note>
                            <paragraph>To utilize the Fibre Channel driver, replace the
                                <literal>volume_driver</literal> line above with:</paragraph>
                            <literal_block xml:space="preserve">volume_driver = cinder.volume.drivers.coprhd.fc.EMCCoprHDFCDriver</literal_block>
                        </note>
                        <note>
                            <paragraph>To utilize the ScaleIO driver, replace the <literal>volume_driver</literal> line
                                above with:</paragraph>
                            <literal_block xml:space="preserve">volume_driver = cinder.volume.drivers.coprhd.fc.EMCCoprHDScaleIODriver</literal_block>
                        </note>
                        <note>
                            <paragraph>Set <literal>coprhd_emulate_snapshot</literal> to True if the CoprHD vpool has
                                VMAX or VPLEX as the back-end storage. For these type of back-end
                                storages, when a user tries to create a snapshot, an actual volume
                                gets created in the back end.</paragraph>
                        </note>
                    </list_item>
                    <list_item>
                        <paragraph>Modify the <literal>rpc_response_timeout</literal> value in <literal>/etc/cinder/cinder.conf</literal> to
                            at least 5 minutes. If this entry does not already exist within the
                            <literal>cinder.conf</literal> file, add it in the <literal>[DEFAULT]</literal> section:</paragraph>
                        <literal_block highlight_args="{}" language="ini" linenos="False" xml:space="preserve">[DEFAULT]
# ...
rpc_response_timeout = 300</literal_block>
                    </list_item>
                    <list_item>
                        <paragraph>Now, restart the <literal>cinder-volume</literal> service.</paragraph>
                    </list_item>
                </enumerated_list>
                <paragraph><strong>Volume type creation and extra specs</strong></paragraph>
                <enumerated_list enumtype="arabic" prefix="" suffix=".">
                    <list_item>
                        <paragraph>Create OpenStack volume types:</paragraph>
                        <literal_block highlight_args="{}" language="console" linenos="False" xml:space="preserve">$ openstack volume type create &lt;typename&gt;</literal_block>
                    </list_item>
                    <list_item>
                        <paragraph>Map the OpenStack volume type to the CoprHD virtual pool:</paragraph>
                        <literal_block highlight_args="{}" language="console" linenos="False" xml:space="preserve">$ openstack volume type set &lt;typename&gt; --property CoprHD:VPOOL=&lt;CoprHD-PoolName&gt;</literal_block>
                    </list_item>
                    <list_item>
                        <paragraph>Map the volume type created to appropriate back-end driver:</paragraph>
                        <literal_block highlight_args="{}" language="console" linenos="False" xml:space="preserve">$ openstack volume type set &lt;typename&gt; --property volume_backend_name=&lt;VOLUME_BACKEND_DRIVER&gt;</literal_block>
                    </list_item>
                </enumerated_list>
            </section>
            <section ids="coprhd-drivers-multiple-back-ends" names="coprhd\ drivers\ -\ multiple\ back-ends">
                <title>CoprHD drivers - Multiple back-ends</title>
                <paragraph><strong>cinder.conf</strong></paragraph>
                <enumerated_list enumtype="arabic" prefix="" suffix=".">
                    <list_item>
                        <paragraph>Add or modify the following entries if you are planning to use multiple
                            back-end drivers:</paragraph>
                        <literal_block highlight_args="{}" language="ini" linenos="False" xml:space="preserve">enabled_backends = coprhddriver-iscsi,coprhddriver-fc,coprhddriver-scaleio</literal_block>
                    </list_item>
                    <list_item>
                        <paragraph>Add the following at the end of the file:</paragraph>
                        <literal_block highlight_args="{}" language="ini" linenos="False" xml:space="preserve">[coprhddriver-iscsi]
volume_driver = cinder.volume.drivers.coprhd.iscsi.EMCCoprHDISCSIDriver
volume_backend_name = EMCCoprHDISCSIDriver
coprhd_hostname = &lt;CoprHD Host Name&gt;
coprhd_port = 4443
coprhd_username = &lt;username&gt;
coprhd_password = &lt;password&gt;
coprhd_tenant = &lt;CoprHD-Tenant-Name&gt;
coprhd_project = &lt;CoprHD-Project-Name&gt;
coprhd_varray = &lt;CoprHD-Virtual-Array-Name&gt;


[coprhddriver-fc]
volume_driver = cinder.volume.drivers.coprhd.fc.EMCCoprHDFCDriver
volume_backend_name = EMCCoprHDFCDriver
coprhd_hostname = &lt;CoprHD Host Name&gt;
coprhd_port = 4443
coprhd_username = &lt;username&gt;
coprhd_password = &lt;password&gt;
coprhd_tenant = &lt;CoprHD-Tenant-Name&gt;
coprhd_project = &lt;CoprHD-Project-Name&gt;
coprhd_varray = &lt;CoprHD-Virtual-Array-Name&gt;


[coprhddriver-scaleio]
volume_driver = cinder.volume.drivers.coprhd.scaleio.EMCCoprHDScaleIODriver
volume_backend_name = EMCCoprHDScaleIODriver
coprhd_hostname = &lt;CoprHD Host Name&gt;
coprhd_port = 4443
coprhd_username = &lt;username&gt;
coprhd_password = &lt;password&gt;
coprhd_tenant = &lt;CoprHD-Tenant-Name&gt;
coprhd_project = &lt;CoprHD-Project-Name&gt;
coprhd_varray = &lt;CoprHD-Virtual-Array-Name&gt;
coprhd_scaleio_rest_gateway_host = &lt;ScaleIO Rest Gateway&gt;
coprhd_scaleio_rest_gateway_port = 443
coprhd_scaleio_rest_server_username = &lt;rest gateway username&gt;
coprhd_scaleio_rest_server_password = &lt;rest gateway password&gt;
scaleio_verify_server_certificate = True or False
scaleio_server_certificate_path = &lt;certificate path&gt;</literal_block>
                    </list_item>
                    <list_item>
                        <paragraph>Restart the <literal>cinder-volume</literal> service.</paragraph>
                    </list_item>
                </enumerated_list>
                <paragraph><strong>Volume type creation and extra specs</strong></paragraph>
                <paragraph>Setup the <literal>volume-types</literal> and <literal>volume-type</literal> to <literal>volume-backend</literal>
                    association:</paragraph>
                <literal_block highlight_args="{}" language="console" linenos="False" xml:space="preserve">$ openstack volume type create "CoprHD High Performance ISCSI"
$ openstack volume type set "CoprHD High Performance ISCSI" --property CoprHD:VPOOL="High Performance ISCSI"
$ openstack volume type set "CoprHD High Performance ISCSI" --property volume_backend_name= EMCCoprHDISCSIDriver

$ openstack volume type create "CoprHD High Performance FC"
$ openstack volume type set "CoprHD High Performance FC" --property CoprHD:VPOOL="High Performance FC"
$ openstack volume type set "CoprHD High Performance FC" --property volume_backend_name= EMCCoprHDFCDriver

$ openstack volume type create "CoprHD performance SIO"
$ openstack volume type set "CoprHD performance SIO" --property CoprHD:VPOOL="Scaled Perf"
$ openstack volume type set "CoprHD performance SIO" --property volume_backend_name= EMCCoprHDScaleIODriver</literal_block>
            </section>
        </section>
        <section ids="iscsi-driver-notes" names="iscsi\ driver\ notes">
            <title>ISCSI driver notes</title>
            <bullet_list bullet="*">
                <list_item>
                    <paragraph>The compute host must be added to the CoprHD along with its ISCSI
                        initiator.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>The ISCSI initiator must be associated with IP network on the CoprHD.</paragraph>
                </list_item>
            </bullet_list>
        </section>
        <section ids="fc-driver-notes" names="fc\ driver\ notes">
            <title>FC driver notes</title>
            <bullet_list bullet="*">
                <list_item>
                    <paragraph>The compute host must be attached to a VSAN or fabric discovered
                        by CoprHD.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>There is no need to perform any SAN zoning operations. CoprHD will perform
                        the necessary operations automatically as part of the provisioning process.</paragraph>
                </list_item>
            </bullet_list>
        </section>
        <section ids="scaleio-driver-notes" names="scaleio\ driver\ notes">
            <title>ScaleIO driver notes</title>
            <bullet_list bullet="*">
                <list_item>
                    <paragraph>Install the ScaleIO SDC on the compute host.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>The compute host must be added as the SDC to the ScaleIO MDS
                        using the below commands:</paragraph>
                    <literal_block xml:space="preserve">/opt/emc/scaleio/sdc/bin/drv_cfg --add_mdm --ip List of MDM IPs
(starting with primary MDM and separated by comma)
Example:
/opt/emc/scaleio/sdc/bin/drv_cfg --add_mdm --ip
10.247.78.45,10.247.78.46,10.247.78.47</literal_block>
                </list_item>
            </bullet_list>
            <paragraph>This step has to be repeated whenever the SDC (compute host in this case)
                is rebooted.</paragraph>
        </section>
        <section ids="consistency-group-configuration" names="consistency\ group\ configuration">
            <title>Consistency group configuration</title>
            <paragraph>To enable the support of consistency group and consistency group snapshot
                operations, use a text editor to edit the file <literal>/etc/cinder/policy.json</literal> and
                change the values of the below fields as specified. Upon editing the file,
                restart the <literal>c-api</literal> service:</paragraph>
            <literal_block xml:space="preserve">"consistencygroup:create" : "",
"consistencygroup:delete": "",
"consistencygroup:get": "",
"consistencygroup:get_all": "",
"consistencygroup:update": "",
"consistencygroup:create_cgsnapshot" : "",
"consistencygroup:delete_cgsnapshot": "",
"consistencygroup:get_cgsnapshot": "",
"consistencygroup:get_all_cgsnapshots": "",</literal_block>
        </section>
        <section ids="names-of-resources-in-back-end-storage" names="names\ of\ resources\ in\ back-end\ storage">
            <title>Names of resources in back-end storage</title>
            <paragraph>All the resources like volume, consistency group, snapshot, and consistency
                group snapshot will use the display name in OpenStack for naming in the
                back-end storage.</paragraph>
        </section>
    </section>
</document>
