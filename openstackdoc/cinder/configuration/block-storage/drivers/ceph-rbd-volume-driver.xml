<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE document PUBLIC "+//IDN docutils.sourceforge.net//DTD Docutils Generic//EN//XML" "http://docutils.sourceforge.net/docs/ref/docutils.dtd">
<!-- Generated by Docutils 0.13.1 -->
<document source="/home/fbaumanis/openstack/soc8_test/openstack_repo/cinder/doc/source/configuration/block-storage/drivers/ceph-rbd-volume-driver.rst">
    <section ids="ceph-rados-block-device-rbd" names="ceph\ rados\ block\ device\ (rbd)">
        <title>Ceph RADOS Block Device (RBD)</title>
        <paragraph>If you use KVM or QEMU as your hypervisor, you can configure the Compute
            service to use <reference name="Ceph RADOS block devices (RBD)" refuri="http://ceph.com/ceph-storage/block-storage/">Ceph RADOS block devices
                (RBD)</reference> for volumes.</paragraph>
        <paragraph>Ceph is a massively scalable, open source, distributed storage system.
            It is comprised of an object store, block store, and a POSIX-compliant
            distributed file system. The platform can auto-scale to the exabyte
            level and beyond. It runs on commodity hardware, is self-healing and
            self-managing, and has no single point of failure. Ceph is in the Linux
            kernel and is integrated with the OpenStack cloud operating system. Due
            to its open-source nature, you can install and use this portable storage
            platform in public or private clouds.</paragraph>
        <figure ids="id1">
            <image candidates="{'*': 'configuration/block-storage/drivers/../../figures/ceph-architecture.png'}" uri="configuration/block-storage/drivers/../../figures/ceph-architecture.png"></image>
            <caption>Ceph architecture</caption>
        </figure>
        <section ids="rados" names="rados">
            <title>RADOS</title>
            <paragraph>Ceph is based on Reliable Autonomic Distributed Object Store (RADOS).
                RADOS distributes objects across the storage cluster and replicates
                objects for fault tolerance. RADOS contains the following major
                components:</paragraph>
            <definition_list>
                <definition_list_item>
                    <term><emphasis>Object Storage Device (OSD) Daemon</emphasis></term>
                    <definition>
                        <paragraph>The storage daemon for the RADOS service, which interacts with the
                            OSD (physical or logical storage unit for your data).
                            You must run this daemon on each server in your cluster. For each
                            OSD, you can have an associated hard drive disk. For performance
                            purposes, pool your hard drive disk with raid arrays, logical volume
                            management (LVM), or B-tree file system (Btrfs) pooling. By default,
                            the following pools are created: data, metadata, and RBD.</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term><emphasis>Meta-Data Server (MDS)</emphasis></term>
                    <definition>
                        <paragraph>Stores metadata. MDSs build a POSIX file
                            system on top of objects for Ceph clients. However, if you do not use
                            the Ceph file system, you do not need a metadata server.</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term><emphasis>Monitor (MON)</emphasis></term>
                    <definition>
                        <paragraph>A lightweight daemon that handles all communications
                            with external applications and clients. It also provides a consensus
                            for distributed decision making in a Ceph/RADOS cluster. For
                            instance, when you mount a Ceph shared on a client, you point to the
                            address of a MON server. It checks the state and the consistency of
                            the data. In an ideal setup, you must run at least three <literal>ceph-mon</literal>
                            daemons on separate servers.</paragraph>
                    </definition>
                </definition_list_item>
            </definition_list>
            <paragraph>Ceph developers recommend XFS for production deployments, Btrfs for
                testing, development, and any non-critical deployments. Btrfs has the
                correct feature set and roadmap to serve Ceph in the long-term, but XFS
                and ext4 provide the necessary stability for todayâ€™s deployments.</paragraph>
            <note>
                <paragraph>If using Btrfs, ensure that you use the correct version (see <reference name="Ceph Dependencies" refuri="http://ceph.com/docs/master/start/os-recommendations/.">Ceph
                        Dependencies</reference>).</paragraph>
                <paragraph>For more information about usable file systems, see
                    <reference name="ceph.com/ceph-storage/file-system/" refuri="http://ceph.com/ceph-storage/file-system/">ceph.com/ceph-storage/file-system/</reference>.</paragraph>
            </note>
        </section>
        <section ids="ways-to-store-use-and-expose-data" names="ways\ to\ store,\ use,\ and\ expose\ data">
            <title>Ways to store, use, and expose data</title>
            <paragraph>To store and access your data, you can use the following storage
                systems:</paragraph>
            <definition_list>
                <definition_list_item>
                    <term><emphasis>RADOS</emphasis></term>
                    <definition>
                        <paragraph>Use as an object, default storage mechanism.</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term><emphasis>RBD</emphasis></term>
                    <definition>
                        <paragraph>Use as a block device. The Linux kernel RBD (RADOS block
                            device) driver allows striping a Linux block device over multiple
                            distributed object store data objects. It is compatible with the KVM
                            RBD image.</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term><emphasis>CephFS</emphasis></term>
                    <definition>
                        <paragraph>Use as a file, POSIX-compliant file system.</paragraph>
                    </definition>
                </definition_list_item>
            </definition_list>
            <paragraph>Ceph exposes RADOS; you can access it through the following interfaces:</paragraph>
            <definition_list>
                <definition_list_item>
                    <term><emphasis>RADOS Gateway</emphasis></term>
                    <definition>
                        <paragraph>OpenStack Object Storage and Amazon-S3 compatible
                            RESTful interface (see <reference name="RADOS_Gateway" refuri="http://ceph.com/wiki/RADOS_Gateway">RADOS_Gateway</reference>).</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term><emphasis>librados</emphasis></term>
                    <definition>
                        <paragraph>and its related C/C++ bindings</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term><emphasis>RBD and QEMU-RBD</emphasis></term>
                    <definition>
                        <paragraph>Linux kernel and QEMU block devices that stripe
                            data across multiple objects.</paragraph>
                    </definition>
                </definition_list_item>
            </definition_list>
        </section>
        <section ids="driver-options" names="driver\ options">
            <title>Driver options</title>
            <paragraph>The following table contains the configuration options supported by the
                Ceph RADOS Block Device driver.</paragraph>
            <note>
                <paragraph>The <literal>volume_tmp_dir</literal> option has been deprecated and replaced by
                    <literal>image_conversion_dir</literal>.</paragraph>
            </note>
            <comment xml:space="preserve">Warning: Do not edit this file. It is automatically generated from the
software project's code and your changes will be overwritten.

The tool to generate this file lives in openstack-doc-tools repository.

Please make any changes needed in the code, then run the
autogenerate-config-doc tool from the openstack-doc-tools repository, or
ask for help on the documentation mailing list, IRC channel or meeting.</comment>
            <target refid="cinder-storage-ceph"></target>
            <table classes="config-ref-table" ids="id2 cinder-storage-ceph" names="cinder-storage_ceph">
                <title>Description of Ceph storage configuration options</title>
                <tgroup cols="2">
                    <colspec colwidth="50"></colspec>
                    <colspec colwidth="50"></colspec>
                    <thead>
                        <row>
                            <entry>
                                <paragraph>Configuration option = Default value</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Description</paragraph>
                            </entry>
                        </row>
                    </thead>
                    <tbody>
                        <row>
                            <entry>
                                <paragraph><strong>[DEFAULT]</strong></paragraph>
                            </entry>
                            <entry>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rados_connect_timeout</literal> = <literal>-1</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Integer) Timeout value (in seconds) used when connecting to ceph cluster. If value &lt; 0, no timeout is set and default librados value is used.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rados_connection_interval</literal> = <literal>5</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Integer) Interval value (in seconds) between connection retries to ceph cluster.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rados_connection_retries</literal> = <literal>3</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Integer) Number of retries if connection to ceph cluster failed.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rbd_ceph_conf</literal> =</paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) Path to the ceph configuration file</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rbd_cluster_name</literal> = <literal>ceph</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) The name of ceph cluster</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rbd_flatten_volume_from_snapshot</literal> = <literal>False</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Boolean) Flatten volumes created from snapshots to remove dependency from volume to snapshot</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rbd_max_clone_depth</literal> = <literal>5</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Integer) Maximum number of nested volume clones that are taken before a flatten occurs. Set to 0 to disable cloning.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rbd_pool</literal> = <literal>rbd</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) The RADOS pool where rbd volumes are stored</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rbd_secret_uuid</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) The libvirt uuid of the secret for the rbd_user volumes</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rbd_store_chunk_size</literal> = <literal>4</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Integer) Volumes will be chunked into objects of this size (in megabytes).</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>rbd_user</literal> = <literal>None</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(String) The RADOS client name for accessing rbd volumes - only set when using cephx authentication</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph><literal>replication_connect_timeout</literal> = <literal>5</literal></paragraph>
                            </entry>
                            <entry>
                                <paragraph>(Integer) Timeout value (in seconds) used when connecting to ceph cluster to do a demotion/promotion of volumes. If value &lt; 0, no timeout is set and default librados value is used.</paragraph>
                            </entry>
                        </row>
                    </tbody>
                </tgroup>
            </table>
        </section>
    </section>
</document>
