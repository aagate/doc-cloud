<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE document PUBLIC "+//IDN docutils.sourceforge.net//DTD Docutils Generic//EN//XML" "http://docutils.sourceforge.net/docs/ref/docutils.dtd">
<!-- Generated by Docutils 0.13.1 -->
<document source="/home/fbaumanis/openstack/soc8_test/openstack_repo/nova/doc/source/admin/arch.rst">
    <section ids="system-architecture" names="system\ architecture">
        <title>System architecture</title>
        <paragraph>OpenStack Compute contains several main components.</paragraph>
        <bullet_list bullet="-">
            <list_item>
                <paragraph>The cloud controller represents the global state and interacts with the
                    other components. The <literal>API server</literal> acts as the web services front end for
                    the cloud controller. The <literal>compute controller</literal> provides compute server
                    resources and usually also contains the Compute service.</paragraph>
            </list_item>
            <list_item>
                <paragraph>The <literal>object store</literal> is an optional component that provides storage
                    services; you can also use OpenStack Object Storage instead.</paragraph>
            </list_item>
            <list_item>
                <paragraph>An <literal>auth manager</literal> provides authentication and authorization services when
                    used with the Compute system; you can also use OpenStack Identity as a
                    separate authentication service instead.</paragraph>
            </list_item>
            <list_item>
                <paragraph>A <literal>volume controller</literal> provides fast and permanent block-level storage for
                    the compute servers.</paragraph>
            </list_item>
            <list_item>
                <paragraph>The <literal>network controller</literal> provides virtual networks to enable compute
                    servers to interact with each other and with the public network. You can also
                    use OpenStack Networking instead.</paragraph>
            </list_item>
            <list_item>
                <paragraph>The <literal>scheduler</literal> is used to select the most suitable compute controller to
                    host an instance.</paragraph>
            </list_item>
        </bullet_list>
        <paragraph>Compute uses a messaging-based, <literal>shared nothing</literal> architecture. All major
            components exist on multiple servers, including the compute, volume, and
            network controllers, and the Object Storage or Image service.  The state of the
            entire system is stored in a database. The cloud controller communicates with
            the internal object store using HTTP, but it communicates with the scheduler,
            network controller, and volume controller using Advanced Message Queuing
            Protocol (AMQP). To avoid blocking a component while waiting for a response,
            Compute uses asynchronous calls, with a callback that is triggered when a
            response is received.</paragraph>
        <section ids="hypervisors" names="hypervisors">
            <title>Hypervisors</title>
            <paragraph>Compute controls hypervisors through an API server. Selecting the best
                hypervisor to use can be difficult, and you must take budget, resource
                constraints, supported features, and required technical specifications into
                account. However, the majority of OpenStack development is done on systems
                using KVM and Xen-based hypervisors. For a detailed list of features and
                support across different hypervisors, see the <reference name="Feature Support Matrix" refuri="https://docs.openstack.org/developer/nova/support-matrix.html">Feature Support Matrix</reference><target ids="feature-support-matrix" names="feature\ support\ matrix" refuri="https://docs.openstack.org/developer/nova/support-matrix.html"></target>.</paragraph>
            <paragraph>You can also orchestrate clouds using multiple hypervisors in different
                availability zones. Compute supports the following hypervisors:</paragraph>
            <bullet_list bullet="-">
                <list_item>
                    <paragraph><reference name="Baremetal" refuri="https://docs.openstack.org/ironic/latest/">Baremetal</reference></paragraph>
                </list_item>
                <list_item>
                    <paragraph><reference name="Docker" refuri="https://www.docker.io">Docker</reference></paragraph>
                </list_item>
                <list_item>
                    <paragraph><reference name="Hyper-V" refuri="http://www.microsoft.com/en-us/server-cloud/hyper-v-server/default.aspx">Hyper-V</reference></paragraph>
                </list_item>
                <list_item>
                    <paragraph><reference name="Kernel-based Virtual Machine (KVM)" refuri="http://www.linux-kvm.org/page/Main_Page">Kernel-based Virtual Machine (KVM)</reference></paragraph>
                </list_item>
                <list_item>
                    <paragraph><reference name="Linux Containers (LXC)" refuri="https://linuxcontainers.org/">Linux Containers (LXC)</reference></paragraph>
                </list_item>
                <list_item>
                    <paragraph><reference name="Quick Emulator (QEMU)" refuri="http://wiki.qemu.org/Manual">Quick Emulator (QEMU)</reference></paragraph>
                </list_item>
                <list_item>
                    <paragraph><reference name="User Mode Linux (UML)" refuri="http://user-mode-linux.sourceforge.net/">User Mode Linux (UML)</reference></paragraph>
                </list_item>
                <list_item>
                    <paragraph><reference name="VMware vSphere" refuri="http://www.vmware.com/products/vsphere-hypervisor/support.html">VMware vSphere</reference></paragraph>
                </list_item>
                <list_item>
                    <paragraph><reference name="Xen" refuri="http://www.xen.org/support/documentation.html">Xen</reference></paragraph>
                </list_item>
            </bullet_list>
            <paragraph>For more information about hypervisors, see
                <reference internal="True" refuri="configuration/hypervisors"><inline classes="doc">Hypervisors</inline></reference>
                section in the Nova Configuration Reference.</paragraph>
        </section>
        <section ids="projects-users-and-roles" names="projects,\ users,\ and\ roles">
            <title>Projects, users, and roles</title>
            <paragraph>The Compute system is designed to be used by different consumers in the form of
                projects on a shared system, and role-based access assignments.  Roles control
                the actions that a user is allowed to perform.</paragraph>
            <paragraph>Projects are isolated resource containers that form the principal
                organizational structure within the Compute service. They consist of an
                individual VLAN, and volumes, instances, images, keys, and users. A user can
                specify the project by appending <literal>project_id</literal> to their access key.  If no
                project is specified in the API request, Compute attempts to use a project with
                the same ID as the user.</paragraph>
            <paragraph>For projects, you can use quota controls to limit the:</paragraph>
            <bullet_list bullet="-">
                <list_item>
                    <paragraph>Number of volumes that can be launched.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Number of processor cores and the amount of RAM that can be allocated.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Floating IP addresses assigned to any instance when it launches. This allows
                        instances to have the same publicly accessible IP addresses.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Fixed IP addresses assigned to the same instance when it launches.  This
                        allows instances to have the same publicly or privately accessible IP
                        addresses.</paragraph>
                </list_item>
            </bullet_list>
            <paragraph>Roles control the actions a user is allowed to perform. By default, most
                actions do not require a particular role, but you can configure them by editing
                the <literal>policy.json</literal> file for user roles. For example, a rule can be defined so
                that a user must have the <literal>admin</literal> role in order to be able to allocate a
                public IP address.</paragraph>
            <paragraph>A project limits users' access to particular images. Each user is assigned a
                user name and password. Keypairs granting access to an instance are enabled for
                each user, but quotas are set, so that each project can control resource
                consumption across available hardware resources.</paragraph>
            <note>
                <paragraph>Earlier versions of OpenStack used the term <literal>tenant</literal> instead of
                    <literal>project</literal>. Because of this legacy terminology, some command-line tools use
                    <literal>--tenant_id</literal> where you would normally expect to enter a project ID.</paragraph>
            </note>
        </section>
        <section ids="block-storage" names="block\ storage">
            <title>Block storage</title>
            <paragraph>OpenStack provides two classes of block storage: ephemeral storage and
                persistent volume.</paragraph>
            <rubric>Ephemeral storage</rubric>
            <paragraph>Ephemeral storage includes a root ephemeral volume and an additional ephemeral
                volume.</paragraph>
            <paragraph>The root disk is associated with an instance, and exists only for the life of
                this very instance. Generally, it is used to store an instance's root file
                system, persists across the guest operating system reboots, and is removed on
                an instance deletion. The amount of the root ephemeral volume is defined by the
                flavor of an instance.</paragraph>
            <paragraph>In addition to the ephemeral root volume, all default types of flavors, except
                <literal>m1.tiny</literal>, which is the smallest one, provide an additional ephemeral block
                device sized between 20 and 160 GB (a configurable value to suit an
                environment). It is represented as a raw block device with no partition table
                or file system. A cloud-aware operating system can discover, format, and mount
                such a storage device. OpenStack Compute defines the default file system for
                different operating systems as Ext4 for Linux distributions, VFAT for non-Linux
                and non-Windows operating systems, and NTFS for Windows. However, it is
                possible to specify any other filesystem type by using <literal>virt_mkfs</literal> or
                <literal>default_ephemeral_format</literal> configuration options.</paragraph>
            <note>
                <paragraph>For example, the <literal>cloud-init</literal> package included into an Ubuntu's stock
                    cloud image, by default, formats this space as an Ext4 file system and
                    mounts it on <literal>/mnt</literal>. This is a cloud-init feature, and is not an OpenStack
                    mechanism. OpenStack only provisions the raw storage.</paragraph>
            </note>
            <rubric>Persistent volume</rubric>
            <paragraph>A persistent volume is represented by a persistent virtualized block device
                independent of any particular instance, and provided by OpenStack Block
                Storage.</paragraph>
            <paragraph>Only a single configured instance can access a persistent volume.  Multiple
                instances cannot access a persistent volume. This type of configuration
                requires a traditional network file system to allow multiple instances
                accessing the persistent volume. It also requires a traditional network file
                system like NFS, CIFS, or a cluster file system such as GlusterFS. These
                systems can be built within an OpenStack cluster, or provisioned outside of it,
                but OpenStack software does not provide these features.</paragraph>
            <paragraph>You can configure a persistent volume as bootable and use it to provide a
                persistent virtual instance similar to the traditional non-cloud-based
                virtualization system. It is still possible for the resulting instance to keep
                ephemeral storage, depending on the flavor selected. In this case, the root
                file system can be on the persistent volume, and its state is maintained, even
                if the instance is shut down. For more information about this type of
                configuration, see <reference name="Introduction to the Block Storage service" refuri="https://docs.openstack.org/cinder/latest/configuration/block-storage/block-storage-overview.html">Introduction to the Block Storage service</reference><target ids="introduction-to-the-block-storage-service" names="introduction\ to\ the\ block\ storage\ service" refuri="https://docs.openstack.org/cinder/latest/configuration/block-storage/block-storage-overview.html"></target>
                in the OpenStack Configuration Reference.</paragraph>
            <note>
                <paragraph>A persistent volume does not provide concurrent access from multiple
                    instances. That type of configuration requires a traditional network file
                    system like NFS, or CIFS, or a cluster file system such as GlusterFS. These
                    systems can be built within an OpenStack cluster, or provisioned outside of
                    it, but OpenStack software does not provide these features.</paragraph>
            </note>
        </section>
        <section ids="ec2-compatibility-api" names="ec2\ compatibility\ api">
            <title>EC2 compatibility API</title>
            <target refid="index-0"></target>
            <todo_node classes="admonition-todo" ids="index-0">
                <title>Todo</title>
                <paragraph>Does this need to be removed now?</paragraph>
            </todo_node>
            <paragraph>In addition to the native compute API, OpenStack provides an EC2-compatible
                API. This API allows EC2 legacy workflows built for EC2 to work with OpenStack.</paragraph>
            <warning>
                <paragraph>Nova in tree EC2-compatible API is deprecated.  The <reference name="ec2-api project" refuri="https://git.openstack.org/cgit/openstack/ec2-api/">ec2-api project</reference><target ids="ec2-api-project" names="ec2-api\ project" refuri="https://git.openstack.org/cgit/openstack/ec2-api/"></target> is working to
                    implement the EC2 API.</paragraph>
            </warning>
            <paragraph>You can use numerous third-party tools and language-specific SDKs to interact
                with OpenStack clouds. You can use both native and compatibility APIs. Some of
                the more popular third-party tools are:</paragraph>
            <definition_list>
                <definition_list_item>
                    <term>Euca2ools</term>
                    <definition>
                        <paragraph>A popular open source command-line tool for interacting with the EC2 API.
                            This is convenient for multi-cloud environments where EC2 is the common API,
                            or for transitioning from EC2-based clouds to OpenStack. For more
                            information, see the <reference name="Eucalyptus Documentation" refuri="http://docs.hpcloud.com/eucalyptus">Eucalyptus Documentation</reference>.</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term>Hybridfox</term>
                    <definition>
                        <paragraph>A Firefox browser add-on that provides a graphical interface to many popular
                            public and private cloud technologies, including OpenStack.  For more
                            information, see the <reference name="hybridfox site" refuri="http://code.google.com/p/hybridfox/">hybridfox site</reference>.</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term>boto</term>
                    <definition>
                        <paragraph>Python library for interacting with Amazon Web Services. You can use this
                            library to access OpenStack through the EC2 compatibility API.  For more
                            information, see the <reference name="boto project page on GitHub" refuri="https://github.com/boto/boto">boto project page on GitHub</reference>.</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term>fog</term>
                    <definition>
                        <paragraph>A Ruby cloud services library. It provides methods to interact with a large
                            number of cloud and virtualization platforms, including OpenStack. For more
                            information, see the <reference name="fog site" refuri="https://rubygems.org/gems/fog">fog site</reference>.</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term>php-opencloud</term>
                    <definition>
                        <paragraph>A PHP SDK designed to work with most OpenStack-based cloud deployments, as
                            well as Rackspace public cloud. For more information, see the <reference name="php-opencloud site" refuri="http://www.php-opencloud.com">php-opencloud
                                site</reference>.</paragraph>
                    </definition>
                </definition_list_item>
            </definition_list>
        </section>
        <section ids="building-blocks" names="building\ blocks">
            <title>Building blocks</title>
            <paragraph>In OpenStack the base operating system is usually copied from an image stored
                in the OpenStack Image service. This is the most common case and results in an
                ephemeral instance that starts from a known template state and loses all
                accumulated states on virtual machine deletion. It is also possible to put an
                operating system on a persistent volume in the OpenStack Block Storage volume
                system. This gives a more traditional persistent system that accumulates states
                which are preserved on the OpenStack Block Storage volume across the deletion
                and re-creation of the virtual machine. To get a list of available images on
                your system, run:</paragraph>
            <literal_block highlight_args="{}" language="console" linenos="False" xml:space="preserve">$ openstack image list
+--------------------------------------+-----------------------------+--------+
| ID                                   | Name                        | Status |
+--------------------------------------+-----------------------------+--------+
| aee1d242-730f-431f-88c1-87630c0f07ba | Ubuntu 14.04 cloudimg amd64 | active |
| 0b27baa1-0ca6-49a7-b3f4-48388e440245 | Ubuntu 14.10 cloudimg amd64 | active |
| df8d56fc-9cea-4dfd-a8d3-28764de3cb08 | jenkins                     | active |
+--------------------------------------+-----------------------------+--------+</literal_block>
            <paragraph>The displayed image attributes are:</paragraph>
            <definition_list>
                <definition_list_item>
                    <term><literal>ID</literal></term>
                    <definition>
                        <paragraph>Automatically generated UUID of the image</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term><literal>Name</literal></term>
                    <definition>
                        <paragraph>Free form, human-readable name for image</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term><literal>Status</literal></term>
                    <definition>
                        <paragraph>The status of the image. Images marked <literal>ACTIVE</literal> are available for use.</paragraph>
                    </definition>
                </definition_list_item>
                <definition_list_item>
                    <term><literal>Server</literal></term>
                    <definition>
                        <paragraph>For images that are created as snapshots of running instances, this is the
                            UUID of the instance the snapshot derives from. For uploaded images, this
                            field is blank.</paragraph>
                    </definition>
                </definition_list_item>
            </definition_list>
            <paragraph>Virtual hardware templates are called <literal>flavors</literal>. By default, these are
                configurable by admin users, however that behavior can be changed by redefining
                the access controls for <literal>compute_extension:flavormanage</literal> in
                <literal>/etc/nova/policy.json</literal> on the <literal>compute-api</literal> server.</paragraph>
            <paragraph>For a list of flavors that are available on your system:</paragraph>
            <literal_block highlight_args="{}" language="console" linenos="False" xml:space="preserve">$ openstack flavor list
+-----+-----------+-------+------+-----------+-------+-----------+
| ID  | Name      |   RAM | Disk | Ephemeral | VCPUs | Is_Public |
+-----+-----------+-------+------+-----------+-------+-----------+
| 1   | m1.tiny   |   512 |    1 |         0 |     1 | True      |
| 2   | m1.small  |  2048 |   20 |         0 |     1 | True      |
| 3   | m1.medium |  4096 |   40 |         0 |     2 | True      |
| 4   | m1.large  |  8192 |   80 |         0 |     4 | True      |
| 5   | m1.xlarge | 16384 |  160 |         0 |     8 | True      |
+-----+-----------+-------+------+-----------+-------+-----------+</literal_block>
        </section>
        <section ids="compute-service-architecture" names="compute\ service\ architecture">
            <title>Compute service architecture</title>
            <paragraph>These basic categories describe the service architecture and information about
                the cloud controller.</paragraph>
            <rubric>API server</rubric>
            <paragraph>At the heart of the cloud framework is an API server, which makes command and
                control of the hypervisor, storage, and networking programmatically available
                to users.</paragraph>
            <paragraph>The API endpoints are basic HTTP web services which handle authentication,
                authorization, and basic command and control functions using various API
                interfaces under the Amazon, Rackspace, and related models. This enables API
                compatibility with multiple existing tool sets created for interaction with
                offerings from other vendors. This broad compatibility prevents vendor lock-in.</paragraph>
            <rubric>Message queue</rubric>
            <paragraph>A messaging queue brokers the interaction between compute nodes (processing),
                the networking controllers (software which controls network infrastructure),
                API endpoints, the scheduler (determines which physical hardware to allocate to
                a virtual resource), and similar components. Communication to and from the
                cloud controller is handled by HTTP requests through multiple API endpoints.</paragraph>
            <paragraph>A typical message passing event begins with the API server receiving a request
                from a user. The API server authenticates the user and ensures that they are
                permitted to issue the subject command. The availability of objects implicated
                in the request is evaluated and, if available, the request is routed to the
                queuing engine for the relevant workers.  Workers continually listen to the
                queue based on their role, and occasionally their type host name. When an
                applicable work request arrives on the queue, the worker takes assignment of
                the task and begins executing it. Upon completion, a response is dispatched to
                the queue which is received by the API server and relayed to the originating
                user.  Database entries are queried, added, or removed as necessary during the
                process.</paragraph>
            <rubric>Compute worker</rubric>
            <paragraph>Compute workers manage computing instances on host machines. The API dispatches
                commands to compute workers to complete these tasks:</paragraph>
            <bullet_list bullet="-">
                <list_item>
                    <paragraph>Run instances</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Delete instances (Terminate instances)</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Reboot instances</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Attach volumes</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Detach volumes</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Get console output</paragraph>
                </list_item>
            </bullet_list>
            <rubric>Network Controller</rubric>
            <paragraph>The Network Controller manages the networking resources on host machines. The
                API server dispatches commands through the message queue, which are
                subsequently processed by Network Controllers. Specific operations include:</paragraph>
            <bullet_list bullet="-">
                <list_item>
                    <paragraph>Allocating fixed IP addresses</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Configuring VLANs for projects</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Configuring networks for compute nodes</paragraph>
                </list_item>
            </bullet_list>
        </section>
    </section>
</document>
